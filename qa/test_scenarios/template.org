#+TODO: TODO STARTED FAILED | DONE SKIPPED
# The vertical bar indicates which states are final states.

* TODO Template for tests plan for cwdaemon version X
Version of template: 2023.05.16.
** TODO <Machine/OS identifier>
<Additional info about machine, OS, libs, compiler>
OS:
C compiler:
libc:
libcw:

*** TODO Build system tests
**** TODO make distcheck
*Steps*
Run "make distcheck" in main directory of the project.

*Expected result*
1. Distribution package is built correctly (no errors during creation of
   archive).
2. Automatic tests executed during 'make distcheck' pass.
3. The distribution package contains all files intended for distribution (use
   your best judgement here).

*Actual result*

**** TODO ./configure flags

Test that all flags supported by ./configure script produce "buildable" code.

*Steps*
Run ./qa/test_configure_flags.sh

*Expected result*

The script should not report any failure.

Example of failed test:

$ qa/test_configure_flags.sh
128: ./configure --enable-dev --disable-xcwcp --disable-cwcp --disable-pulseaudio --disable-alsa --disable-oss --disable-console &>/dev/null && make &>/dev/null && make check &>/dev/null && make clean &>/dev/null
Test of configuration flags FAILED
$ echo $?
255

Example of successful test:

$ qa/test_configure_flags.sh
128: ./configure --enable-dev --disable-xcwcp --disable-cwcp --disable-pulseaudio --disable-alsa --disable-oss --disable-console &>/dev/null && make &>/dev/null && make check &>/dev/null && make clean &>/dev/null
127: ./configure --enable-dev --disable-xcwcp --disable-cwcp --disable-pulseaudio --disable-alsa --disable-oss &>/dev/null && make &>/dev/null && make check &>/dev/null && make clean &>/dev/null
126: ./configure --enable-dev --disable-xcwcp --disable-cwcp --disable-pulseaudio --disable-alsa --disable-console &>/dev/null && make &>/dev/null && make check &>/dev/null && make clean &>/dev/null
[...]
3: ./configure --disable-oss &>/dev/null && make &>/dev/null && make check &>/dev/null && make clean &>/dev/null
2: ./configure --disable-console &>/dev/null && make &>/dev/null && make check &>/dev/null && make clean &>/dev/null
1: ./configure &>/dev/null && make &>/dev/null && make check &>/dev/null && make clean &>/dev/null
Test of configuration flags SUCCEEDED


*Notes*
The shell script may not work on systems without bash.

*Actual result*


**** TODO regresion with make distcheck

Confirm that failure of 'make distcheck' after specific sequence of steps does not occur.

On Alpine 3.17 and with certain version of tests/unit_tests/Makefile.am, the
steps ended with compilation error, and distribution package was not created.

The error message was:

gcc  -g -O2 -Wall -Wextra -pedantic -Wswitch-default -Wimplicit-function-declaration -Wswitch-enum -Wfloat-equal -Wpointer-arith -Wcast-qual -Wwrite-strings -Wmissing-prototypes -Wstrict-prototypes -Wmissing-declarations -Wredundant-decls -Wduplicated-cond -Wduplicated-branches -Wlogical-op -Wrestrict -Wnull-dereference -Wjump-misses-init -Wdouble-promotion -Wshadow -Wformat=2 -std=c99   -o utils ../../src/utils-utils.o utils-utils.o  
/usr/lib/gcc/x86_64-alpine-linux-musl/12.2.1/../../../../x86_64-alpine-linux-musl/bin/ld: cannot find utils-utils.o: No such file or directory
collect2: error: ld returned 1 exit status
make[4]: *** [Makefile:328: utils] Error 1
make[4]: Leaving directory '/home/acerion/cwdaemon/git_repo/cwdaemon-0.12.0/_build/sub/tests/unit_tests'



*Steps*
make distclean
autoreconf
automake
./configure
make
make check
make distcheck  # <---- In this step a compilation error was occurring


*Expected result*
Distribution archive is created correctly.

*Actual result*

*** TODO unit tests

Tests implemented in tests/unit_tests.

*Steps*
1. ./configure --enable-functional-tests
2. make check

*Expected result*
All unit tests should have "PASS" status in output of "make check" command.

PASS: unit_tests/daemon_utils
PASS: unit_tests/daemon_options
PASS: unit_tests/tests_random
PASS: unit_tests/tests_time_utils

*Notes*

Count of unit tests depends on whether you pass "--enable-functional-tests"
to ./configure or not. Test both cases.

*Actual result*

*** TODO fuzzing tests
**** TODO simple fuzzing test

Run simple fuzzing test: tests/fuzzing/simple/test_program.

Run the test early in testing phase, certainly before doing manual tests. Let
an automatic test detect problems early.



*Preconditions*

1. Be sure to use large count of iterations in the test: set value of
   "n_iters" in test_run() to high value.

2. Be sure to run the test under valgrind: set "supervisor_id" to
   "supervisor_id_valgrind" in options passed to server_start().

3. Be sure to have all tests enabled in "g_test_cases[]".



*Expected result*

1. valgrind reports no memory leaks (with possible exception of memory leak
   described in ticket R0018.

2. valgrind reports no memory errors of other types.

3. cwdaemon's test framework doesn't report any errors on its own



*Actual result*

*** TODO gcov/lcov

Purpose: confirm that it's possible to generate a coverage report for unit
tests.

*Steps*

The steps are copied from relevant sections in top-level README file:

1. ./configure --enable-gcov
2. make gcov
3. <web browser> tests/unit_tests/coverage/index.html
4. make gcov-clean

*Expected results*
1. Summary of configuration step correctly shows enabled gcov,
2. There are no errors during generation of gcov/lcov report,
3. Contents of the report looks correct (no obvious problems with the
   report).
4. There are no errors during cleanup step.

*** TODO functional tests

**** TODO Tests written in Perl


Execute each and every perl script in tests/ directory.

*Preconditions*

cwdaemon must be started (automatically or manually), running on default
port, with <platform's preferred sound system>.

./src/cwdaemon -n -x p

*Expected result*
All tests pass

*Actual result*

***** TODO tests/cwtest.pl

*Expected result*
Test passes

*Actual result*


***** TODO tests/cwtest_esc2.pl
*Expected result*
Test passes

*Actual result*



***** TODO tests/cwtest_esc3.pl
*Expected result*
Test passes

*Actual result*



***** TODO tests/cwtest_esc64.pl
*Expected result*
Test passes

*Actual result*



***** TODO tests/cwtest_esc7.pl
*Expected result*
Test passes

*Actual result*



***** TODO tests/cwtest_esc8.pl

*Notes*

Make sure that user with which cwdaemon is running is in a group which has
"rw" permissions for /dev/ttyS0. The test checks different devices, and one
of devices should be a valid, accessible tty device. ttyS0 is such a device
(unless you plugged in an USB-to-UART converter and ttyUSB0 is also
available).

*Expected result*

1. cwdaemon doesn't crash when is asked to access different keying devices,
   including non-existent ones.
2. Test program passes.

*Actual result*

***** TODO tests/cwtest_esca.pl
*Expected result*
Test passes

*Actual result*



***** TODO tests/cwtest_escc.pl
*Expected result*
Test passes

*Actual result*



***** TODO tests/cwtest_escd.pl
*Expected result*
Test passes

*Actual result*



***** TODO tests/cwtest_escf.pl

For this test you may want to start cwdaemon with "info" log level, to see
information about switching of sound system:
./src/cwdaemon -n -x p -y i

*Expected result*
Test passes

*Actual result*



***** TODO tests/cwtest_escg.pl
*Expected result*
Test passes

*Actual result*



***** TODO tests/cwtest_short_space.pl
*Expected result*
Test passes

*Actual result*

**** TODO Tests written in C

Execute each and every binary in tests/test_00X*. Run each of them manually
to see the debugs printed in console.

*Preconditions*
1. Plug in USB-to-UART converter to USB socket.
2. ./configure --enable-functional-tests
3. make check (fix compiler error about files from unixcw)


*Expected result*
All tests pass

*Actual result*



***** TODO tests/test_001_basic_process_control
*Expected result*
Test passes

*Actual result*



***** TODO tests/test_002_reset_register_callback
*Expected result*
Test passes

*Actual result*



***** TODO tests/test_003_cwdevice_tty_line_options
*Expected result*
Test passes

*Actual result*

**** TODO Manual tests of cwdaemon

***** TODO Command-line options

****** TODO '-I'/'--libcwflags'

Confirm that option that specifies debug flags for libcw is working.

In this test cwdaemon is executed:
 - in non-daemonized mode to observe console logs;
 - with null keying device because null device is the lowest common denominator;


*Steps*

1. Open connection to cwdaemon.

   nc -u localhost 6789
   OR
   nc -u 127.0.0.1 6789

2. Run cwdaemon without the tested flag. Notice the 'd' threshold for cwdaemon.

   ./src/cwdaemon -d null -n -x p -y d

3. Send some characters to cwdaemon with nc.

4. Confirm that cwdaemon's log output shows cwdaemon logs, but doesn't show
   any libcw logs (because '--libcwflags' option is not provided).

5. Kill cwdaemon started in step 2. Start cwdaemon with '--libcwflags'
   option. Notice the 'd' (DEBUG) threshold for cwdaemon.

   ./src/cwdaemon --libcwflags=4294967295 -d null  -n -x p -y d

6. Send characters to cwdaemon using nc.

7. Confirm that cwdaemon's log output shows cwdaemon logs and show libcw logs
   with severity INFO or DEBUG.

8. Kill cwdaemon started in step 4. Start cwdaemon with '--libcwflags'
   option. Notice the 'w' (WARNING) threshold for cwdaemon.

   ./src/cwdaemon --libcwflags=4294967295 -d null  -n -x p -y w

9. Send characters to cwdaemon using nc.

10. Confirm that cwdaemon's log output shows cwdaemon logs. If there are any
	libcw logs, the logs have severity only WARNING or ERROR.

*Expected result*

1. libcw logs are visible in cwdaemon's log output only if `--libcwflags`
   flag is used

2. Threshold for libcw logs depends on value of '-y' flag.

*Actual result*



*** TODO memory tests with valgrind
**** TODO memory tests with valgrind for functional/automatic tests

*Goal*

Run all of cwdaemon's automatic functional tests in a setup where cwdaemon is
running under control of valgrind.


*Steps*

1. Enable compilation of manual functional tests

   ./configure --enable-functional-tests --enable-long-functional-tests

2. Compile cwdaemon

   make && make check

3. Prepare environment variables that will be used by all test programs
   executed with "make check"

   export CWDAEMON_TEST_SOUND_SYSTEM=null
   export CWDAEMON_TEST_SUPERVISOR=valgrind

4. Compile and run the tests.

   make check

5. After tests are completed:

   1. Look for sections in test logs that contain valgrind's summary of memory leaks.

	  Look for "HEAP SUMMARY" and "LEAK SUMMARY" section headers in *.log
      files.

   2. Look for sections in test logs that contain valgrind's summary of
      memory errors.

	  Look for "ERROR SUMMARY" section header in *.log files

   3. Confirm that no memory leaks or memory errors were reported by
      valgrind.


*Expected result*

1. no memory leaks or memory errors were reported by valgrind.

*Actual result*

**** TODO memory tests with valgrind for functional/manual tests

*Goal*

Run selected cwdaemon's manual functional tests in a setup where cwdaemon is
running under control of valgrind.


*Steps*

1. Enable compilation of manual functional tests

   ./configure --enable-functional-tests --enable-long-functional-tests

2. Compile

   make && make check

3. Run the test. Use command line options necessary to enable and use valgrind

   ./tests/functional_tests/manual/feature_multiple_requests/test_program --sound-system null --supervisor valgrind

4. After test is completed:

   1. Confirm that cwdaemon has exited correctly, without errors.

   2. Confirm that there are no memory leaks or memory errors reported in
      valgrind's log.

	  Look for "HEAP SUMMARY" and "LEAK SUMMARY" section headers the log.
	  Look for "ERROR SUMMARY" section header in the log.


*Expected result*

1. cwdaemon didn't crash.

2. no memory leaks or memory errors were reported by valgrind.

*Actual result*

**** TODO memory tests with valgrind for fuzzing tests

*Goal*

Run all of cwdaemon's fuzzing tests in a setup where cwdaemon is running
under control of valgrind.


*Steps*

1. Confirm that fuzzing tests done few sections above were already executed
   with cwdaemon being under control of valgrind.

*Expected result*

No additional test is needed here because the primary fuzzing tests already
use valgrind.

*Actual result*

